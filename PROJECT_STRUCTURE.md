# ML Prediction API - Project Structure

This document outlines the comprehensive structure of the ML Prediction API project with MLOps best practices.

## Overview

A production-ready machine learning prediction API with comprehensive MLOps features including:
- ğŸš€ FastAPI-based prediction service for Housing and Iris models
- ğŸ”„ Data Version Control (DVC) for reproducible ML pipelines
- ğŸ“Š Prometheus + Grafana monitoring stack
- ğŸ³ Docker containerization with multi-stage builds
- ğŸ”§ GitHub Actions CI/CD pipeline
- ğŸ“ˆ MLflow experiment tracking and model registry
- ğŸ§ª Comprehensive testing suite
- ğŸ“ Automated logging and error tracking

## Directory Layout

```
mlops_assignment/
â”œâ”€â”€ README.md                           # Main project overview and setup guide
â”œâ”€â”€ Makefile                           # Development and deployment commands
â”œâ”€â”€ run_api.py                         # Local API runner script
â”œâ”€â”€ requirements.txt                   # Python dependencies
â”œâ”€â”€ Dockerfile                         # Multi-stage Docker build configuration
â”œâ”€â”€ docker-compose.yml                # Basic Docker Compose setup
â”œâ”€â”€ .dockerignore                      # Docker ignore patterns
â”œâ”€â”€ PROJECT_STRUCTURE.md               # This file - comprehensive project structure
â”‚
â”œâ”€â”€ src/                              # Core application source code
â”‚   â”œâ”€â”€ api.py                        # FastAPI application with enhanced model loading
â”‚   â”œâ”€â”€ logger.py                     # Structured logging with multiple handlers
â”‚   â”œâ”€â”€ schemas.py                    # Pydantic models and API contracts
â”‚   â”œâ”€â”€ prometheus_metrics.py         # Comprehensive Prometheus metrics collection
â”‚   â”œâ”€â”€ model_retraining.py          # Automated model retraining workflows
â”‚   â”œâ”€â”€ model_evaluation.py          # Model evaluation and comparison (DVC)
â”‚   â”œâ”€â”€ data_pipeline.py             # Data preprocessing pipeline
â”‚   â”œâ”€â”€ train_housing.py             # Housing price prediction model training
â”‚   â”œâ”€â”€ train_iris.py                # Iris classification model training
â”‚   â”œâ”€â”€ data_load_housing.py         # Housing dataset loading and preprocessing
â”‚   â””â”€â”€ data_load_iris.py            # Iris dataset loading and preprocessing
â”‚
â”œâ”€â”€ tests/                            # Comprehensive test suite
â”‚   â”œâ”€â”€ __init__.py                   # Test package initialization
â”‚   â”œâ”€â”€ test_api.py                   # API endpoint integration tests
â”‚   â”œâ”€â”€ test_advanced_features.py    # Advanced ML features testing
â”‚   â””â”€â”€ test_logging.py              # Logging functionality unit tests
â”‚
â”œâ”€â”€ scripts/                          # Deployment and utility scripts
â”‚   â””â”€â”€ deploy_local.sh               # Enhanced local deployment with health checks
â”‚
â”œâ”€â”€ monitoring/                       # Complete monitoring stack
â”‚   â”œâ”€â”€ monitor.py                    # Real-time monitoring dashboard
â”‚   â”œâ”€â”€ prometheus.yml                # Prometheus scraping configuration
â”‚   â”œâ”€â”€ grafana-dashboard.json        # Legacy dashboard (deprecated)
â”‚   â”œâ”€â”€ docker-compose-monitoring.yml # Monitoring services orchestration
â”‚   â”‚
â”‚   â””â”€â”€ grafana/                      # Grafana configuration structure
â”‚       â”œâ”€â”€ dashboards/               # Dashboard definitions
â”‚       â”‚   â””â”€â”€ ml-dashboard.json     # ML metrics dashboard with Prometheus datasource
â”‚       â””â”€â”€ provisioning/             # Auto-provisioning configuration
â”‚           â”œâ”€â”€ datasources/          # Datasource configurations
â”‚           â”‚   â””â”€â”€ prometheus.yml    # Prometheus datasource (prometheus:9090)
â”‚           â””â”€â”€ dashboards/           # Dashboard provisioning
â”‚               â””â”€â”€ dashboard.yml     # Dashboard provider configuration
â”‚
â”œâ”€â”€ config/                           # Configuration management
â”‚   â”œâ”€â”€ pyproject.toml               # Black, isort, and tool configurations
â”‚   â””â”€â”€ pytest.ini                   # Pytest configuration and coverage settings
â”‚
â”œâ”€â”€ .github/                          # GitHub Actions CI/CD workflows
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci-cd.yml                # Complete CI/CD pipeline with actual deployment
â”‚
â”œâ”€â”€ logs/                            # Application logging
â”‚   â”œâ”€â”€ api.log                      # Structured API application logs
â”‚   â””â”€â”€ predictions.db               # SQLite prediction audit trail
â”‚
â”œâ”€â”€ data/                            # Dataset storage
â”‚   â”œâ”€â”€ housing_raw.csv              # Raw housing market data
â”‚   â”œâ”€â”€ housing_processed.csv        # Cleaned and preprocessed housing data
â”‚   â”œâ”€â”€ iris_raw.csv                 # Raw iris classification dataset
â”‚   â””â”€â”€ iris_processed.csv           # Preprocessed iris features
â”‚
â”œâ”€â”€ mlruns/                          # MLflow experiment tracking
â”‚   â””â”€â”€ [experiment_id]/             # Experiment run artifacts
â”‚       â”œâ”€â”€ artifacts/               # Model artifacts and metadata
â”‚       â”œâ”€â”€ metrics/                 # Training and validation metrics
â”‚       â””â”€â”€ params/                  # Hyperparameters and configuration
â”‚
â”œâ”€â”€ .dvc/                            # DVC version control system
â”‚   â”œâ”€â”€ config                       # DVC configuration
â”‚   â””â”€â”€ cache/                       # DVC cached artifacts
â”‚
â”œâ”€â”€ dvc.yaml                         # DVC pipeline definition (6-stage ML workflow)
â”œâ”€â”€ dvc.lock                         # DVC pipeline lock file
â”œâ”€â”€ params.yaml                      # DVC pipeline parameters
â”‚
â””â”€â”€ models/                          # Model registry and artifacts
    â”œâ”€â”€ housing/                     # Housing prediction models
    â”‚   â”œâ”€â”€ model.pkl                # Trained model artifacts
    â”‚   â””â”€â”€ metrics.json             # Model performance metrics
    â””â”€â”€ iris/                        # Iris classification models
        â”œâ”€â”€ model.pkl                # Trained model artifacts
        â””â”€â”€ metrics.json             # Model performance metrics
```

## Key Features & Components

### ğŸ¤– Machine Learning Pipeline
- **Models**: Housing price prediction (regression) + Iris classification
- **Training**: Automated training scripts with MLflow tracking
- **Evaluation**: Comprehensive model evaluation and comparison
- **Registry**: MLflow model registry with versioning

### ğŸ”„ Data Version Control (DVC)
- **Pipeline Stages**:
  1. `data_preparation` - Raw data loading and validation
  2. `feature_engineering` - Feature preprocessing and transformation
  3. `train_housing` - Housing model training with hyperparameters
  4. `train_iris` - Iris model training and optimization
  5. `model_evaluation` - Cross-model performance comparison
  6. `deployment_validation` - Production readiness checks
- **Reproducibility**: Parameterized pipelines with `params.yaml`
- **Artifacts**: Versioned models, metrics, and datasets

### ğŸš€ API Service
- **Framework**: FastAPI with automatic OpenAPI documentation
- **Endpoints**: Health checks, model info, predictions, metrics
- **Model Loading**: Multi-strategy loading (MLflow, local files, training fallback)
- **Error Handling**: Comprehensive error responses and logging
- **Validation**: Pydantic schema validation for all inputs/outputs

### ğŸ“Š Monitoring & Observability
- **Metrics**: Prometheus metrics for requests, predictions, errors, latency
- **Dashboards**: Grafana dashboards with ML-specific visualizations
- **Logging**: Structured logging with multiple output formats
- **Health Checks**: Container and service health monitoring
- **Alerting**: Performance and error rate monitoring

### ğŸ³ Containerization
- **Multi-stage Build**: Optimized Docker images with model training
- **Orchestration**: Docker Compose for local development
- **Networking**: Proper service discovery (prometheus:9090, ml-api:8000)
- **Volumes**: Persistent storage for models, logs, and metrics

### ğŸ”§ CI/CD Pipeline
- **Stages**: Lint â†’ Test â†’ Build â†’ Deploy â†’ Verify
- **Quality Gates**: Black, isort, flake8, pytest with coverage
- **Deployment**: Automated local deployment with health verification
- **Monitoring**: Optional monitoring stack deployment
- **Artifacts**: Docker image building and registry push

### ğŸ§ª Testing Strategy
- **Unit Tests**: Core functionality and edge cases
- **Integration Tests**: API endpoints and workflows
- **Coverage**: Automated coverage reporting with Codecov
- **Fixtures**: Reusable test data and mock objects

## Usage Examples

### ğŸƒ Quick Start
```bash
# Clone and setup
git clone <repository>
cd mlops_assignment
pip install -r requirements.txt

# Train models
cd src && python data_pipeline.py && python train_housing.py && python train_iris.py

# Run API
python run_api.py

# Access API docs
open http://localhost:8000/docs
```

### ğŸ”„ DVC Workflow
```bash
# Reproduce entire pipeline
dvc repro

# Run specific stage
dvc repro train_housing

# Show pipeline status
dvc dag

# Check metrics
dvc metrics show
```

### ğŸ³ Docker Deployment
```bash
# API only
./scripts/deploy_local.sh

# Full stack (API + monitoring)
./scripts/deploy_comprehensive.sh --full

# Check status
./scripts/deploy_comprehensive.sh --status
```

### ğŸ“Š Monitoring Access
- **API Documentation**: http://localhost:8000/docs
- **Health Check**: http://localhost:8000/health
- **Prometheus Metrics**: http://localhost:9090
- **Grafana Dashboard**: http://localhost:3000 (admin/admin)
- **API Metrics**: http://localhost:8000/metrics/prometheus

### ğŸ§ª Testing Commands
```bash
# Run all tests
pytest tests/ -v --cov=src

# Run specific test categories
pytest tests/test_api.py -v
pytest tests/test_advanced_features.py -v

# Generate coverage report
pytest --cov=src --cov-report=html
```

### ğŸ”§ Development Workflow
```bash
# Format code
python -m black src/
python -m isort src/

# Lint code  
python -m flake8 src/

# Run quality checks
python -m black --check src/
python -m isort --check-only src/
python -m flake8 src/
```

## Environment Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `MLFLOW_TRACKING_URI` | `file:./mlruns` | MLflow tracking server URI |
| `API_PORT` | `8000` | FastAPI service port |
| `LOG_LEVEL` | `INFO` | Application logging level |
| `DEPLOY_MONITORING` | `false` | Deploy monitoring stack in CI/CD |
| `PROMETHEUS_PORT` | `9090` | Prometheus metrics port |
| `GRAFANA_PORT` | `3000` | Grafana dashboard port |

## Troubleshooting

### Common Issues
1. **Model Loading Failures**: Check MLflow registry and model artifacts
2. **Prometheus Connection**: Verify service names in docker-compose
3. **Grafana Datasource**: Ensure Prometheus URL is `http://prometheus:9090`
4. **Port Conflicts**: Check for existing services on ports 8000, 9090, 3000

### Debug Commands
```bash
# Check container logs
docker logs ml-api-local
docker logs monitoring_prometheus_1

# Verify model availability
curl http://localhost:8000/models/info

# Check Prometheus targets
curl http://localhost:9090/api/v1/targets
```
